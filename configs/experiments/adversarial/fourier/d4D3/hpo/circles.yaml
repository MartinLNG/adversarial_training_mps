# @package _global_
experiment: hpo

defaults:
  - override /born: fourier/d4D3
  - override /dataset: 2Dtoy/circles_4k
  - override /trainer/classification: null
  - override /trainer/adversarial: pgd_at
  - override /trainer/ganstyle: null
  - override /trainer/generative: null
  - override /tracking: online
  - override /hydra/sweeper: optuna

model_path: outputs/seed_sweep/cls/fourier/d4D3/circles_4k_1802/3/models/circles_4k_pre_mps_bd3_fourier4_300adamlr0.021609636715243675wd3.445426647309657e-07

dataset:
  split_seed: 11
  gen_dow_kwargs:
    seed: 25

tracking:
  project: gan_train
  entity: martin-nissen-gonzalez-heidelberg-university
  mode: online
  seed: 4
  sampling:
    num_bins: 200
    num_spc: 1024
    batch_spc: 16
    method: secant
  evasion:
    method: PGD
    norm: 2
    criterion:
      name: negative log-likelihood
      kwargs:
        eps: 1.0e-08
    strengths:
    - 0.1

trainer:
  adversarial:
    max_epoch: 300
    batch_size: 256
    method: "pgd_at"
    stop_crit: "rob"
    patience: 300
    watch_freq: 10000
    metrics: {"rob": 1, "acc": 1}

    evasion:
      method: "PGD"
      norm: "inf"
      criterion:
        name: "negative log-likelihood"
        kwargs:
          eps: 1e-8
      strengths: [0.15]
      num_steps: 10
      step_size: null
      random_start: true

    curriculum: true
    curriculum_start: 0.01
    curriculum_end_epoch: 200

    save: false
    auto_stack: true
    auto_unbind: false

hydra:
  sweeper:
    storage: null
    study_name: "${experiment}_${dataset.name}"
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 42
      n_startup_trials: 10
    direction: minimize
    n_trials: 30
    n_jobs: 1
    params:
      trainer.adversarial.optimizer.kwargs.lr: tag(log, interval(1e-5, 1e-2))
      trainer.adversarial.optimizer.kwargs.weight_decay: tag(log, interval(1e-9, 1e-1))
      trainer.adversarial.clean_weight: interval(0.0, 0.95)
