# @package _global_
# HPO for learning rate only, with no weight decay
experiment: lr_hpo

defaults:
  - override /born: d30D18
  - override /dataset: 2Dtoy/moons_4k
  - override /trainer/classification: adam500_loss
  - override /trainer/ganstyle: null
  - override /trainer/adversarial: null
  - override /tracking: online
  - override /hydra/sweeper: optuna

trainer:
  classification:
    save: True
    optimizer:
      kwargs:
        weight_decay: 0.0
        lr: 5e-3


tracking:
  sampling:
    num_bins: 500
    num_spc: 1000

hydra:
  sweeper:
    study_name: "${experiment}"

    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 42
      n_startup_trials: 10

    direction: minimize
    n_trials: 100
    n_jobs: 1

    params:
      tracking.seed: range(1,100)
      tracking.random_state: range(1,100)
