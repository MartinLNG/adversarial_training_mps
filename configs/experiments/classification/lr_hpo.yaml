# @package _global_
# HPO for learning rate only, with no weight decay
experiment: lr_hpo

defaults:
  - override /born: d30D18
  - override /dataset: 2Dtoy/spirals_4k
  - override /trainer/classification: adam500_loss
  - override /trainer/ganstyle: null
  - override /trainer/adversarial: null
  - override /tracking: online
  - override /hydra/sweeper: optuna

trainer:
  classification:
    save: True
    optimizer:
      kwargs:
        weight_decay: 0.0

hydra:
  sweeper:
    storage: "sqlite:////home/ubuntu/adversarial_training_mps/outputs/${experiment}_study.db"
    study_name: "${experiment}"

    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 42
      n_startup_trials: 10

    direction: minimize
    n_trials: 40
    n_jobs: 1

    params:
      trainer.classification.optimizer.kwargs.lr: tag(log, interval(1e-4, 5e-2))
      tracking.seed: range(1,100)
      tracking.random_state: range(1,100)
