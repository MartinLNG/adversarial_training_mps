max_epoch: 5
critic:
  backbone:
    architecture: mlp # see above for examples
    model_kwargs: {hidden_multipliers: [3.0, 3.0, 3.0], nonlinearity: LeakyReLU, negative_slope: 0.01}
  head:
    class_aware: True # of the classes
    architecture: linear # see above for examples
    model_kwargs: {}
  discrimination: 
    max_epoch_pre: 40
    max_epoch_gan: 10
    batch_size: 32
    optimizer:
      name: "adam"
      kwargs:
        lr: 1e-4
        weight_decay: 0.00
    patience: 25
  criterion:
    name: "BCE"
    kwargs: null
sampling:
  num_bins: 200
  num_spc: 64
  batch_spc: 8
  method: secant
r_real: 1.0 # ratio n_real = n_synth * r_real
optimizer:
  name: "adam"
  kwargs:
    lr: 1e-4
    weight_decay: 0.00
watch_freq: 1
metrics: {"loss": 1, "acc": 1, "rob": 1}
retrain_crit: "acc"
tolerance: 0.05
retrain:
  max_epoch: 4
  batch_size: 64 # samples loaded per categorisation step for all classes involved
  criterion: 
    name: "negative log-likelihood"
    kwargs:
      eps: 1e-8
  optimizer:
    name: "adam"
    kwargs:
      lr: 1e-4
      weight_decay: 0.00
  auto_stack: True
  auto_unbind: False
  patience: 50
  stop_crit: "acc"
  watch_freq: 1
  metrics: {"loss": 1, "acc": 1}
  save: False
save: False

