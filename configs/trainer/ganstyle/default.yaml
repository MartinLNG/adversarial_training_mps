max_epoch: 100
critic:
  backbone:
    architecture: mlp # see above for examples
    model_kwargs: {hidden_multipliers: [8.0, 8.0, 8.0], nonlinearity: LeakyReLU, negative_slope: 0.01}
  head:
    class_aware: True # of the classes
    architecture: linear # see above for examples
    model_kwargs: {}
  discrimination: 
    max_epoch_pre: 100
    max_epoch_gan: 10
    batch_size: 32
    optimizer:
      name: "adam"
      kwargs:
        lr: 1e-4
        weight_decay: 0.00
    patience: 25
  criterion:
    name: "BCE"
    kwargs: null
sampling:
  num_bins: 200
  num_spc: 128
  batch_spc: 16
  method: secant
r_real: 1.0 # ratio n_real = n_synth * r_real
optimizer:
  name: "adam"
  kwargs:
    lr: 1e-4
    weight_decay: 0.00
watch_freq: 100
metrics: {"loss": 1, "acc": 1, "rob": 10, "viz": 10, "fid": 10}
retrain_crit: "acc"
tolerance: 0.05
retrain:
  max_epoch: 40
  batch_size: 256 # samples loaded per categorisation step for all classes involved
  criterion: 
    name: "negative log-likelihood"
    kwargs:
      eps: 1e-8
  optimizer:
    name: "adam"
    kwargs:
      lr: 1e-4
      weight_decay: 0.00
  auto_stack: True
  auto_unbind: False
  patience: 30
  stop_crit: "acc"
  watch_freq: 100
  metrics: {"acc": 10}
  save: False
save: False

